{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd45028",
   "metadata": {},
   "source": [
    "\n",
    "Summary of the entire light curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06f439",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\goran.backlund\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\lightkurve\\search.py:420: LightkurveWarning: Warning: 50 files available to download. Only the first file has been downloaded. Please use `download_all()` or specify additional criteria (e.g. quarter, campaign, or sector) to limit your search.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   object_id          mean_flux                std_flux            min_flux  \\\n",
      "0  Kepler-10  1.000000767967474  0.00025242359231566954  0.9964630043209389   \n",
      "\n",
      "             max_flux      skew    kurtosis          transit_depth  label  \n",
      "0  1.0130792930093226  9.046216  444.959539  0.0035366380288088806      1  \n"
     ]
    }
   ],
   "source": [
    "import lightkurve as lk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "targets = [\"Kepler-10\"]\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for target in targets:\n",
    "    try:\n",
    "        lc = lk.search_lightcurve(target, mission=\"Kepler\").download()\n",
    "        if lc is None:\n",
    "            continue\n",
    "\n",
    "        lc = lc.remove_nans().normalize().flatten(window_length=401)\n",
    "\n",
    "        flux = lc.flux.value\n",
    "        time = lc.time.value\n",
    "\n",
    "        # Enkla features\n",
    "        f_mean = np.mean(flux)\n",
    "        f_std = np.std(flux)\n",
    "        f_min = np.min(flux)\n",
    "        f_max = np.max(flux)\n",
    "        f_skew = skew(flux)\n",
    "        f_kurt = kurtosis(flux)\n",
    "\n",
    "        # Transit depth proxy (skillnad mellan median och min)\n",
    "        transit_depth = np.median(flux) - f_min\n",
    "\n",
    "        # Skapa feature-rad\n",
    "        features = {\n",
    "            \"object_id\": target,\n",
    "            \"mean_flux\": f_mean,\n",
    "            \"std_flux\": f_std,\n",
    "            \"min_flux\": f_min,\n",
    "            \"max_flux\": f_max,\n",
    "            \"skew\": f_skew,\n",
    "            \"kurtosis\": f_kurt,\n",
    "            \"transit_depth\": transit_depth,\n",
    "            \"label\": 1 \n",
    "        }\n",
    "\n",
    "        dataset.append(features)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Misslyckades fÃ¶r {target}: {e}\")\n",
    "\n",
    "# GÃ¶r DataFrame\n",
    "df = pd.DataFrame(dataset)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74027c4a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ðŸ§© `build_segmented_dataset()` â€” Function Summary\n",
    "\n",
    "The `build_segmented_dataset()` function takes a **light curve** (from the [Lightkurve](https://docs.lightkurve.org/) library) and converts it into a **segmented, event-labeled dataset** suitable for machine learning.\n",
    "\n",
    "### **Purpose**\n",
    "\n",
    "To break a continuous light curve into smaller overlapping segments, compute statistical features for each segment, and label segments containing significant flux dips as potential transit events.\n",
    "\n",
    "### **How it works**\n",
    "\n",
    "1. **Input:** a `lightkurve.LightCurve` object\n",
    "2. **Segmentation:** divides the flux time series into equal-length windows (`segment_length`)\n",
    "3. **Feature extraction:** computes basic statistical features per segment:\n",
    "\n",
    "   * mean, std, min, max flux\n",
    "   * skewness, kurtosis\n",
    "   * transit depth (median âˆ’ min)\n",
    "4. **Event detection:** flags segments that contain points below\n",
    "   `median_flux - sigma * std_flux`\n",
    "   as **events** (`label = 1`), otherwise **non-events** (`label = 0`)\n",
    "5. **Output:** returns a `pandas.DataFrame` where each row represents one segment.\n",
    "\n",
    "### **Output structure**\n",
    "\n",
    "| segment_start | segment_end | mean_flux | std_flux | min_flux | max_flux | skew | kurtosis | transit_depth | label |\n",
    "| ------------- | ----------- | --------- | -------- | -------- | -------- | ---- | -------- | ------------- | ----- |\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a2adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_segmented_dataset(\n",
    "    lc,\n",
    "    segment_length=200,\n",
    "    overlap=0,\n",
    "    sigma=3,\n",
    "):\n",
    "    \n",
    "\n",
    "    flux = lc.flux.value\n",
    "    time = lc.time.value\n",
    "    n = len(flux)\n",
    "    step = segment_length - overlap\n",
    "\n",
    "    median_flux = np.median(flux)\n",
    "    std_flux = np.std(flux)\n",
    "\n",
    "    # Detektera event (index fÃ¶r dippar)\n",
    "    event_mask = flux < median_flux - sigma * std_flux\n",
    "    event_indices = np.where(event_mask)[0]\n",
    "\n",
    "    segments = []\n",
    "\n",
    "    for start in range(0, n - segment_length, step):\n",
    "        end = start + segment_length\n",
    "        seg_flux = flux[start:end]\n",
    "        seg_time = time[start:end]\n",
    "\n",
    "        features = {\n",
    "            \"segment_start\": seg_time[0],\n",
    "            \"segment_end\": seg_time[-1],\n",
    "            \"mean_flux\": np.mean(seg_flux),\n",
    "            \"std_flux\": np.std(seg_flux),\n",
    "            \"min_flux\": np.min(seg_flux),\n",
    "            \"max_flux\": np.max(seg_flux),\n",
    "            \"skew\": skew(seg_flux),\n",
    "            \"kurtosis\": kurtosis(seg_flux),\n",
    "            \"transit_depth\": np.median(seg_flux) - np.min(seg_flux),\n",
    "        }\n",
    "\n",
    "       \n",
    "        if np.any((event_indices >= start) & (event_indices < end)):\n",
    "            features[\"label\"] = 1\n",
    "        else:\n",
    "            features[\"label\"] = 0\n",
    "\n",
    "        segments.append(features)\n",
    "\n",
    "    df = pd.DataFrame(segments)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac1eb898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   segment_start  segment_end           mean_flux                std_flux  \\\n",
      "0     200.324085   200.459628  0.9999955480072467  0.00020480690782619156   \n",
      "1     200.460310   200.595853  1.0000114228342825  0.00022028633787149135   \n",
      "2     200.596534   200.732078  0.9999900579346955  0.00021593210217208254   \n",
      "3     200.732759   200.868302  1.0000173306553606  0.00022584174972427093   \n",
      "4     200.868983   201.004527  0.9999970499217118  0.00024485229373302504   \n",
      "\n",
      "             min_flux            max_flux      skew  kurtosis  \\\n",
      "0  0.9994147368777393  1.0005761126734776 -0.121301  0.225332   \n",
      "1  0.9993707576952258  1.0006799623168925 -0.083657  0.059639   \n",
      "2  0.9993596873381183  1.0006687408361072  0.165235  0.024089   \n",
      "3  0.9994191459645783  1.0008826107314164  0.273535  0.892788   \n",
      "4  0.9993573279598602  1.0007581800268617  0.317908  0.112242   \n",
      "\n",
      "           transit_depth  label  object_id  \n",
      "0  0.0005810315734758875      0  Kepler-10  \n",
      "1  0.0006421155866287442      0  Kepler-10  \n",
      "2  0.0006269020104003875      0  Kepler-10  \n",
      "3  0.0005967073947890089      0  Kepler-10  \n",
      "4  0.0006306325657114975      0  Kepler-10  \n"
     ]
    }
   ],
   "source": [
    "df_segments = build_segmented_dataset(lc, segment_length=200, sigma=3)\n",
    "\n",
    "df_segments[\"object_id\"] = \"Kepler-10\"\n",
    "print(df_segments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cdae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_segments = []\n",
    "\n",
    "for target in [\"Kepler-10\", \"Kepler-11\", \"Kepler-12\"]:\n",
    "    search = lk.search_lightcurve(target, mission=\"Kepler\", quarter=10)\n",
    "    lc = search.download().remove_nans().normalize().flatten(window_length=401)\n",
    "    \n",
    "    df = build_segmented_dataset(lc, segment_length=200, sigma=5)\n",
    "    df[\"target_id\"] = target\n",
    "    all_segments.append(df)\n",
    "\n",
    "# Merge all targets into one DataFrame\n",
    "df_all = pd.concat(all_segments, ignore_index=True)\n",
    "df_all.to_csv(\"transit_segments_all.csv\", index=False)\n",
    "\n",
    "print(\"âœ… Saved combined dataset for all targets.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
